{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f18104d",
   "metadata": {},
   "source": [
    "# Running SATURN\n",
    "\n",
    "This notebook will demonstrate how to run SATURN and review the output files.\n",
    "\n",
    "Make sure to run through `dataloader.ipynb` first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2868cb",
   "metadata": {},
   "source": [
    "First, make the run csv file.\n",
    "\n",
    "It should have format:\n",
    "\n",
    "|path|species|embedding path|\n",
    "|-----|------|--------------|\n",
    "|path to frog|frog|frog embeddings path|\n",
    "|path to zebrafish|zebrafish|zebrafish embeddings path|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe9e21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>species</th>\n",
       "      <th>embedding_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frog.h5ad</td>\n",
       "      <td>frog</td>\n",
       "      <td>/home/tcroll/protein_embeddings_export/ESM2/fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/zebrafish.h5ad</td>\n",
       "      <td>zebrafish</td>\n",
       "      <td>/home/tcroll/protein_embeddings_export/ESM2/ze...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  path    species   \n",
       "0       data/frog.h5ad       frog  \\\n",
       "1  data/zebrafish.h5ad  zebrafish   \n",
       "\n",
       "                                      embedding_path  \n",
       "0  /home/tcroll/protein_embeddings_export/ESM2/fr...  \n",
       "1  /home/tcroll/protein_embeddings_export/ESM2/ze...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the csv\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.DataFrame(columns=[\"path\", \"species\", \"embedding_path\"])\n",
    "df[\"species\"] = [\"frog\", \"zebrafish\"]\n",
    "df[\"path\"] = [\"data/frog.h5ad\", \"data/zebrafish.h5ad\"]\n",
    "\n",
    "##### CHANGE THESE PATHS #####\n",
    "frog_embedding_path = os.path.join(os.environ['HOME'], 'protein_embeddings_export', 'ESM2', 'frog_embedding.torch')# \"/dfs/project/cross-species/yanay/data/proteome/embeddings/Xenopus_tropicalis.Xenopus_tropicalis_v9.1.gene_symbol_to_embedding_ESM2.pt\"\n",
    "zebrafish_embedding_path = os.path.join(os.environ['HOME'], 'protein_embeddings_export', 'ESM2', 'zebrafish_embedding.torch')# \"/dfs/project/cross-species/yanay/data/proteome/embeddings/Danio_rerio.GRCz11.gene_symbol_to_embedding_ESM2.pt\"\n",
    "##############################\n",
    "df[\"embedding_path\"] = [frog_embedding_path, zebrafish_embedding_path]\n",
    "df.to_csv(\"data/frog_zebrafish_run.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f50ea9d",
   "metadata": {},
   "source": [
    "# Scoring while training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4669598",
   "metadata": {},
   "source": [
    "We will score our model output while training. To do that, we will need a scoring csv file. We have provided one in this dataset at `data/frog_zebrafish_cell_type_map.csv`. It looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e07a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>frog_cell_type</th>\n",
       "      <th>zebrafish_cell_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Blastula</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Germline</td>\n",
       "      <td>Germline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Neuroectoderm</td>\n",
       "      <td>Neuroectoderm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Non-neural ectoderm</td>\n",
       "      <td>Non-neural ectoderm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Involuting marginal zone</td>\n",
       "      <td>Involuting marginal zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Spemann organizer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Endoderm</td>\n",
       "      <td>Endoderm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Epidermal progenitor</td>\n",
       "      <td>Epidermal progenitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Ionocyte</td>\n",
       "      <td>Ionocyte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Goblet cell</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            frog_cell_type       zebrafish_cell_type\n",
       "0           0                  Blastula                       NaN\n",
       "1           1                  Germline                  Germline\n",
       "2           2             Neuroectoderm             Neuroectoderm\n",
       "3           3       Non-neural ectoderm       Non-neural ectoderm\n",
       "4           4  Involuting marginal zone  Involuting marginal zone\n",
       "5           5         Spemann organizer                       NaN\n",
       "6           6                  Endoderm                  Endoderm\n",
       "7           7      Epidermal progenitor      Epidermal progenitor\n",
       "8           8                  Ionocyte                  Ionocyte\n",
       "9           9               Goblet cell                       NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/frog_zebrafish_cell_type_map.csv\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e20f848",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedf240b",
   "metadata": {},
   "source": [
    "We can see `train-saturn.py`'s potential arguments with `--help`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af1b9263",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "usage: train-saturn.py [-h] [--in_data IN_DATA] [--device DEVICE]\n",
      "                       [--device_num DEVICE_NUM] [--time_stamp TIME_STAMP]\n",
      "                       [--org ORG] [--log_dir LOG_DIR] [--work_dir WORK_DIR]\n",
      "                       [--seed SEED] [--in_label_col IN_LABEL_COL]\n",
      "                       [--ref_label_col REF_LABEL_COL]\n",
      "                       [--tissue_subset TISSUE_SUBSET]\n",
      "                       [--tissue_column TISSUE_COLUMN] [--hv_genes HV_GENES]\n",
      "                       [--hv_span HV_SPAN] [--num_macrogenes NUM_MACROGENES]\n",
      "                       [--centroids_init_path CENTROIDS_INIT_PATH]\n",
      "                       [--embedding_model {ESM1b,MSA1b,protXL,ESM1b_protref,ESM2}]\n",
      "                       [--vae [VAE]] [--hidden_dim HIDDEN_DIM]\n",
      "                       [--model_dim MODEL_DIM]\n",
      "                       [--binarize_expression [BINARIZE_EXPRESSION]]\n",
      "                       [--scale_expression [SCALE_EXPRESSION]]\n",
      "                       [--pretrain [PRETRAIN]]\n",
      "                       [--pretrain_model_path PRETRAIN_MODEL_PATH]\n",
      "                       [--pretrain_lr PRETRAIN_LR]\n",
      "                       [--pretrain_batch_size PRETRAIN_BATCH_SIZE]\n",
      "                       [--l1_penalty L1_PENALTY]\n",
      "                       [--pe_sim_penalty PE_SIM_PENALTY]\n",
      "                       [--pretrain_epochs PRETRAIN_EPOCHS]\n",
      "                       [--unfreeze_macrogenes [UNFREEZE_MACROGENES]]\n",
      "                       [--mnn [MNN]] [--use_ref_labels [USE_REF_LABELS]]\n",
      "                       [--batch_size BATCH_SIZE] [--metric_lr METRIC_LR]\n",
      "                       [--epochs EPOCHS]\n",
      "                       [--balance_pretrain [BALANCE_PRETRAIN]]\n",
      "                       [--equalize_triplets_species [EQUALIZE_TRIPLETS_SPECIES]]\n",
      "                       [--balance_species_cells [BALANCE_SPECIES_CELLS]]\n",
      "                       [--non_species_batch_col NON_SPECIES_BATCH_COL]\n",
      "                       [--polling_freq POLLING_FREQ]\n",
      "                       [--score_adatas [SCORE_ADATAS]]\n",
      "                       [--ct_map_path CT_MAP_PATH]\n",
      "                       [--score_ref_labels [SCORE_REF_LABELS]]\n",
      "\n",
      "Set model hyperparametrs.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --in_data IN_DATA     Path to csv containing input datas and species\n",
      "                        (default: None)\n",
      "  --device DEVICE       Set GPU/CPU (default: cuda)\n",
      "  --device_num DEVICE_NUM\n",
      "                        Set GPU Number (default: 0)\n",
      "  --time_stamp TIME_STAMP\n",
      "                        Add time stamp in file name (default: False)\n",
      "  --org ORG             Add organization to filename (default: saturn)\n",
      "  --log_dir LOG_DIR     Log directory (default: tboard_log/)\n",
      "  --work_dir WORK_DIR   Working directory (default: ./out/)\n",
      "  --seed SEED           Init Seed (default: 0)\n",
      "  --in_label_col IN_LABEL_COL\n",
      "                        Label column for input data (default: None)\n",
      "  --ref_label_col REF_LABEL_COL\n",
      "                        Reference label column for input data (default:\n",
      "                        CL_class_coarse)\n",
      "  --tissue_subset TISSUE_SUBSET\n",
      "                        Subset the input anndatas by the column\n",
      "                        args.tissue_column to just be this tissue (default:\n",
      "                        None)\n",
      "  --tissue_column TISSUE_COLUMN\n",
      "                        When subsetting the input anndatas by the column, use\n",
      "                        this column name. (default: tissue_type)\n",
      "  --hv_genes HV_GENES   Number of highly variable genes (default: 8000)\n",
      "  --hv_span HV_SPAN     Fraction of cells to use when calculating highly\n",
      "                        variable genes, scanpy defeault is 0.3. (default: 0.3)\n",
      "  --num_macrogenes NUM_MACROGENES\n",
      "                        Number of macrogenes (default: 2000)\n",
      "  --centroids_init_path CENTROIDS_INIT_PATH\n",
      "                        Path to existing centroids pretraining weights, or\n",
      "                        location to save to. (default: None)\n",
      "  --embedding_model {ESM1b,MSA1b,protXL,ESM1b_protref,ESM2}\n",
      "                        Gene embedding model whose embeddings should be loaded\n",
      "                        if using gene_embedding_method (default: ESM1b)\n",
      "  --vae [VAE]           Set the embedding layer to be a VAE. (default: False)\n",
      "  --hidden_dim HIDDEN_DIM\n",
      "                        Model first layer hidden dimension (default: 256)\n",
      "  --model_dim MODEL_DIM\n",
      "                        Model latent space dimension (default: 256)\n",
      "  --binarize_expression [BINARIZE_EXPRESSION]\n",
      "                        Whether to binarize the gene expression matrix\n",
      "                        (default: False)\n",
      "  --scale_expression [SCALE_EXPRESSION]\n",
      "                        Whether to scale the gene expression to zero mean and\n",
      "                        unit variance (default: False)\n",
      "  --pretrain [PRETRAIN]\n",
      "                        Pretrain the model (default: True)\n",
      "  --pretrain_model_path PRETRAIN_MODEL_PATH\n",
      "                        Path to save/load a pretraining model to (default:\n",
      "                        None)\n",
      "  --pretrain_lr PRETRAIN_LR\n",
      "                        Pre training Learning learning rate (default: 0.0005)\n",
      "  --pretrain_batch_size PRETRAIN_BATCH_SIZE\n",
      "                        pretrain batch size (default: 4096)\n",
      "  --l1_penalty L1_PENALTY\n",
      "                        L1 Penalty hyperparameter Default is 0. (default: 0.0)\n",
      "  --pe_sim_penalty PE_SIM_PENALTY\n",
      "                        Protein Embedding similarity to Macrogene loss, weight\n",
      "                        hyperparameter. Default is 1.0 (default: 1.0)\n",
      "  --pretrain_epochs PRETRAIN_EPOCHS\n",
      "                        Number of pretraining epochs (default: 200)\n",
      "  --unfreeze_macrogenes [UNFREEZE_MACROGENES]\n",
      "                        Let Metric Learning Modify macrogene weights (default:\n",
      "                        False)\n",
      "  --mnn [MNN]           Use mutual nearest neighbors (default: True)\n",
      "  --use_ref_labels [USE_REF_LABELS]\n",
      "                        Use reference labels when aligning (default: False)\n",
      "  --batch_size BATCH_SIZE\n",
      "                        batch size (default: 4096)\n",
      "  --metric_lr METRIC_LR\n",
      "                        Metric Learning learning rate (default: 0.001)\n",
      "  --epochs EPOCHS       Number of epochs for metric learning (default: 50)\n",
      "  --balance_pretrain [BALANCE_PRETRAIN]\n",
      "                        Balance cell types' weighting in the pretraining model\n",
      "                        (default: False)\n",
      "  --equalize_triplets_species [EQUALIZE_TRIPLETS_SPECIES]\n",
      "                        Balance species' weighting in the metric learning\n",
      "                        model (default: False)\n",
      "  --balance_species_cells [BALANCE_SPECIES_CELLS]\n",
      "                        Balance species' number of cells in all steps by\n",
      "                        resampling randomly. (default: False)\n",
      "  --non_species_batch_col NON_SPECIES_BATCH_COL\n",
      "                        Extra column for batch correction for pretraining. For\n",
      "                        example, the tissue column in atlas data. (default:\n",
      "                        None)\n",
      "  --polling_freq POLLING_FREQ\n",
      "                        Epoch Frequency of scoring during metric learning\n",
      "                        (default: 25)\n",
      "  --score_adatas [SCORE_ADATAS]\n",
      "                        Score the pretraining and metric learning adatas.\n",
      "                        (default: False)\n",
      "  --ct_map_path CT_MAP_PATH\n",
      "                        Path to csv containing label column mappings between\n",
      "                        species (default: /dfs/project/cross-\n",
      "                        species/yanay/fz_true_ct.csv)\n",
      "  --score_ref_labels [SCORE_REF_LABELS]\n",
      "                        Use the ref labels to score instead of the labels.\n",
      "                        (default: False)\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!/usr/conda/bin/python3 ../../train-saturn.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54089dee",
   "metadata": {},
   "source": [
    "We'll train SATURN with the following settings:\n",
    "\n",
    "|Argument|Value|Explanation|\n",
    "|--------|-----|-----------|\n",
    "|in_data|`data/frog_zebrafish_run.csv`|The csv we created containing paths.|\n",
    "|in_label_col|`cell_type`|Use the `cell_type` column labels for metric learning. **NOTE:** SATURN is weakly supervised, it does not share cell type labels across species, so you don't need to match these values across AnnDatas.|\n",
    "|ref_label_col|`cell_type`|Extra cell type argument, will be added to our output but won't effect results since we didn't add `--use_ref_labels|\n",
    "|num_macrogenes|`2000`|By default, we use 2000 macrogenes.|\n",
    "|hv_genes|`8000`|By default, we use the 8000 most highly variable genes.|\n",
    "|centroids_init_path|`saturn_results/fz_centroids.pkl`|Since this is the first time we are runinng this command, we will have to initialize our macrogenes using KMeans, which is an expensive operation. We save that initialization to this location so that if we pass this path to this argument in future runs, we can skip that step.|\n",
    "|score_adata||By adding this flag, we will score our adatas after pretraining and while fine tuning with metric learning.|\n",
    "|ct_map_path|`data/frog_zebrafish_cell_type_map.csv`|The path to our cell type mapping file, needed since we are scoring while training.|\n",
    "|work_dir|`./`|SATURN outputs to a folder called `saturn_results`.|\n",
    "\n",
    "SATURN is very verbose. Some things to check during model training:\n",
    "- Do the AnnData views printed at the start have enough genes? These AnnData views are output after subsetting your input AnnDatas to just the genes that have protein embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a8d0eb",
   "metadata": {},
   "source": [
    "**This command may take some time.**\n",
    "\n",
    "GPU Memory usage: ~8GB for Pretraining, ~10GB total for metric learning but this may very."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d497e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "Using Device 0\n",
      "Set seed to 0\n",
      "After loading the anndata frog View of AnnData object with n_obs × n_vars = 96935 × 9538\n",
      "    obs: 'clusters', 'parent_clusters', 'cell_type', 'n_genes', 'species', 'species_type_label', 'truth_labels', 'ref_labels'\n",
      "    var: 'n_cells'\n",
      "After loading the anndata zebrafish View of AnnData object with n_obs × n_vars = 63371 × 16980\n",
      "    obs: 'n_counts', 'unique_cell_id', 'cell_names', 'library_id', 'batch', 'ClusterID', 'ClusterName', 'TissueID', 'TissueName', 'TimeID', 'cluster', 'cell_type', 'n_genes', 'species', 'species_type_label', 'truth_labels', 'ref_labels'\n",
      "    var: 'n_cells'\n",
      "Making Centroids\n"
     ]
    }
   ],
   "source": [
    "!/usr/conda/bin/python3 ../../train-saturn.py --in_data=data/frog_zebrafish_run.csv \\\n",
    "                              --in_label_col=cell_type --ref_label_col=cell_type \\\n",
    "                              --num_macrogenes=2000     --hv_genes=8000          \\\n",
    "                              --centroids_init_path=saturn_results/fz_centroids.pkl \\\n",
    "                              --score_adata --ct_map_path=data/frog_zebrafish_cell_type_map.csv \\\n",
    "                              --work_dir=. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9742ed19",
   "metadata": {},
   "source": [
    "# Analyze SATURN Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59187961",
   "metadata": {},
   "source": [
    "Let's check what files SATURN outputted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70915522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access './saturn_results': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls ./saturn_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e8c8b",
   "metadata": {},
   "source": [
    "We have a number of log files and \n",
    "- our output AnnData: `test256_data_frog_zebrafish_org_saturn_seed_0.h5ad`\n",
    "- out ouput gene to macrogene weights: `test256_data_frog_zebrafish_org_saturn_seed_0_genes_to_macrogenes.pkl`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd39bfb6",
   "metadata": {},
   "source": [
    "## Load SATURN Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44b1303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "944f9de0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = 'saturn_results/test256_data_frog_zebrafish_org_saturn_seed_0.h5ad', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m adata \u001b[38;5;241m=\u001b[39m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaturn_results/test256_data_frog_zebrafish_org_saturn_seed_0.h5ad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m adata\n",
      "File \u001b[0;32m/usr/conda/lib/python3.10/site-packages/scanpy/readwrite.py:112\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m filename \u001b[38;5;241m=\u001b[39m Path(filename)  \u001b[38;5;66;03m# allow passing strings\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_valid_filename(filename):\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbacked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbacked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfirst_column_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_column_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackup_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackup_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_compression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# generate filename and read to dict\u001b[39;00m\n\u001b[1;32m    125\u001b[0m filekey \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(filename)\n",
      "File \u001b[0;32m/usr/conda/lib/python3.10/site-packages/scanpy/readwrite.py:722\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh5ad\u001b[39m\u001b[38;5;124m'\u001b[39m}:\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sheet \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 722\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_h5ad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbacked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbacked\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    724\u001b[0m         logg\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreading sheet \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msheet\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/conda/lib/python3.10/site-packages/anndata/_io/h5ad.py:224\u001b[0m, in \u001b[0;36mread_h5ad\u001b[0;34m(filename, backed, as_sparse, as_sparse_fmt, chunk_size)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    217\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently only `X` and `raw/X` can be read as sparse.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m         )\n\u001b[1;32m    220\u001b[0m rdasp \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m    221\u001b[0m     read_dense_as_sparse, sparse_format\u001b[38;5;241m=\u001b[39mas_sparse_fmt, axis_chunk\u001b[38;5;241m=\u001b[39mchunk_size\n\u001b[1;32m    222\u001b[0m )\n\u001b[0;32m--> 224\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    225\u001b[0m     d \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;66;03m# Backwards compat for old raw\u001b[39;00m\n",
      "File \u001b[0;32m/usr/conda/lib/python3.10/site-packages/h5py/_hl/files.py:567\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    558\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    559\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    560\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    561\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    562\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    563\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    564\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    565\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    566\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 567\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m/usr/conda/lib/python3.10/site-packages/h5py/_hl/files.py:231\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    230\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 231\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    233\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = 'saturn_results/test256_data_frog_zebrafish_org_saturn_seed_0.h5ad', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "adata = sc.read(\"saturn_results/test256_data_frog_zebrafish_org_saturn_seed_0.h5ad\")\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c976ebc",
   "metadata": {},
   "source": [
    "## Visualize our integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b8a80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.pca(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dcee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca(adata, color=\"species\", title=\"Species\")\n",
    "sc.pl.pca(adata, color=\"labels2\", title=\"Cell Type\") # The original cell type names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7056e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata)\n",
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5cfedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=\"species\", title=\"Species\")\n",
    "sc.pl.umap(adata, color=\"labels2\", title=\"Cell Type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94fc076",
   "metadata": {},
   "source": [
    "# Macrogene Differential Expression\n",
    "\n",
    "With SATURN, we can perform differential expression on macrogenes rather than genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6191ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"saturn_results/test256_data_frog_zebrafish_org_saturn_seed_0_genes_to_macrogenes.pkl\", \"rb\") as f:\n",
    "    macrogene_weights = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ce8689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# macrogene weights is a dictionary of (species_{gene name}) : [gene to macrogen weight](1x2000)\n",
    "macrogene_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8d5d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the adata with macrogenes as the X values\n",
    "macrogene_adata = sc.AnnData(adata.obsm[\"macrogenes\"])\n",
    "macrogene_adata.obs = adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8023996",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.rank_genes_groups(macrogene_adata, groupby=\"labels2\", groups=[\"Ionocyte\"], method=\"wilcoxon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1bc7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.rank_genes_groups_dotplot(macrogene_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7849502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ionocytes_de_df = sc.get.rank_genes_groups_df(macrogene_adata, group=\"Ionocyte\").head(5)\n",
    "ionocytes_de_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4901505",
   "metadata": {},
   "source": [
    "## Investigate these macrogenes by their top ranked genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59331716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(macrogene):\n",
    "    '''\n",
    "    Given the index of a macrogene, return the scores by gene for that centroid\n",
    "    '''\n",
    "    scores = {}\n",
    "    for (gene), score in macrogene_weights.items():\n",
    "        scores[gene] = score[int(macrogene)]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4b1dab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the top macrogenes and their highest weights\n",
    "# NOTE: this will be seed dependent.\n",
    "for macrogene in ionocytes_de_df[\"names\"]:\n",
    "    print(f\"Macrogene {macrogene}\")\n",
    "    display(pd.DataFrame(get_scores(macrogene).items(), columns=[\"gene\", \"weight\"])\\\n",
    "            .sort_values(\"weight\", ascending=False)\\\n",
    "            .head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base (/usr/conda)",
   "language": "python",
   "name": "system_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
